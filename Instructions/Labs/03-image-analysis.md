---
lab:
  title: Azure AI Foundry ポータルで画像を分析する
---

# Azure AI Foundry ポータルで画像を分析する

**Azure AI Vision** には、画像のコンテンツとコンテキストを理解し、画像から情報を抽出するための多数の機能が含まれています。 この演習では、インテリジェント なアプリケーションを作成するための Microsoft のプラットフォームである Azure AI Foundry ポータルで Azure AI Vision を使用し、組み込みの試行エクスペリエンスを使って画像を分析します。 

AI サービスが店舗を監視して支援を必要とする顧客を特定し、従業員に支援を指示する "スマート ストア" を実装することを架空の小売業者 *Northwind Traders* が決定したとします。 Azure AI Vision を使用すると、カメラで撮影した店舗全体の画像が分析されて、画像が表す内容のわかりやすい説明を受け取ることができます。

## Azure AI Foundry ポータルでプロジェクトを作成する

まず、Azure AI Foundry プロジェクトを作成します。

1. Web ブラウザーで [Azure AI Foundry ポータル](https://ai.azure.com) (`https://ai.azure.com`) を開き、Azure 資格情報を使用してサインインします。 初めてサインインするときに開いたヒントまたはクイック スタート ウィンドウを閉じます。また、必要に応じて左上にある **Azure AI Foundry** ロゴを使用してホーム ページに移動します。それは次の画像のようになります (**[ヘルプ]** ウィンドウが開いている場合は閉じます)。

    ![エージェントの作成が選択されている Azure AI Foundry ホーム ページのスクリーンショット。](./media/azure-ai-foundry-home-page.png)

1. ホーム ページで、**[+ エージェントの作成]** を選択します。

1. **エージェントの作成**ウィザードで、プロジェクトの有効な名前を入力します。 

1. **[詳細オプション]** を選択して、次の値を指定します。
    - **Azure AI Foundry リソース**: *既定の名前をそのまま使用します*
    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **リソース グループ**: *リソース グループを作成または選択します*
    - **リージョン**: 次のいずれかの場所を選択してください。
        * 米国東部
        * フランス中部
        * 韓国中部
        * 西ヨーロッパ
        * 米国西部

1. **[作成]** を選択し、構成を確認します。 セットアップ プロセスが完了するまで待ちます。

    >**注**: アクセス許可エラーが発生した場合は、**[修正する]** 　ボタンを選択して、続行する適切なアクセス許可を追加します。

1. プロジェクトが作成されると、既定で Azure AI Foundry ポータルのエージェント プレイグラウンドが表示されます。これは次の図のようになります。

    ![Azure AI Foundry ポータルの Azure AI プロジェクトの詳細のスクリーンショット。](./media/ai-foundry-project-2.png)
 
1. 新しいブラウザー ウィンドウで、[Azure AI サービスの探索ページ](https://ai.azure.com/explore/aiservices)を開きます。

1. *[AI サービス]* ページで、*[Vision + Document]* タイルを選択して、Azure AI Vision とドキュメントの機能を試します。

## 画像のキャプションを生成する

Azure AI Vision の画像キャプション機能を使用して、*Northwind Traders* ストア内のカメラで撮影された画像を分析してみましょう。 画像のキャプションには、**キャプション**機能と**高密度キャプション**機能からアクセスできます。

1. *[Vision + Document]* ページで、下にスクロールし、*[その他のすべての Vision 機能の表示]* の下にある **[画像]** を選択します。 次に、**[画像キャプション]** タイルを選択します。

    ![[Vision and Document] ページの [画像] セクションの [画像キャプション] タイルのスクリーンショット。](./media/vision-image-captioning-tile.png)

1. **[画像にキャプションを追加する]** ページで、**試してみる**という小見出しの下に表示されている接続先のリソースを確認します。 変更を加える必要はありません。 (*注*: リソースの作成時に有効なリソースの場所をカスタマイズしなかった場合は、有効なリージョンにある新しい Azure AI サービスのリソースを作成するように求められる場合があります。 ラボを続行するには、新しいリソースを作成する必要があります)。  

1. [**https://aka.ms/mslearn-images-for-analysis**](https://aka.ms/mslearn-images-for-analysis) を選択して、**image-analysis.zip** をダウンロードします。 ご使用のコンピューターでそのフォルダーを開き、**store-camera-1.jpg** という名前のファイルを見つけます。これには次の画像が含まれています。

    ![Cellphone カメラを使用してストア内の子どもの画像を撮影している親の画像](./media/analyze-images-vision/store-camera-1.jpg)

1. **[ファイルをこちらにドラッグ アンド ドロップ]** ボックスにドラッグするか、ファイル システムでファイルを参照して、**store-camera-1.jpg** イメージをアップロードします。

1. 画像の右側にある **[Detected attributes]\(検出された属性\)** パネルに表示される、生成されたキャプション テキストを確認します。

    **キャプション**機能は、画像の内容を説明し、人間が判読可能な 1 つの英文を提供します。

1. 次に、同じ画像を使用して、**高密度キャプション**を実行します。 ページの上部にある *戻る* 矢印を選択して、**[Vision + Document]** ページに戻ります。 *[Vision + Document]* ページで、**[画像]** タブを選択して、**[高密度キャプション]** タイルを選択します。

    **高密度キャプション**機能は、画像に人間が判読可能な複数のキャプションを提供するという点で、**キャプション**機能とは異なります。1 つは画像のコンテンツを説明し、その他はそれぞれ画像で検出された重要な物体について取り上げます。 検出された各物体には境界ボックスが含まれていて、物体に関連付けられている画像内のピクセル座標を定義します。

1. **[Detected attributes]\(検出された属性\)** の一覧のいずれかのキャプションにカーソルを合わせ、画像内で何が起こるかを観察します。

    ![画像とそのキャプションが表示されています。](./media/analyze-images-vision/dense-captioning.png)

    一覧内の他のキャプションの上にマウス カーソルを移動し、画像内の境界ボックスが移動して、キャプションの生成に使用される画像の部分を強調表示するようすを確認します。

## イメージへのタグ付け 

次に試す機能は、*タグの抽出*機能です。 タグの抽出は、数千個の認識可能な物体 (生物、風景、行動など) に基づきます。

1. Azure AI Foundry の *[Vision + Document]* ページに戻り、**[画像]** タブを選択し、**[一般的なタグ抽出]** タイルを選択します。

1. ダウンロードした画像を含むフォルダーを開き、次のような **store-image-2.jpg** という名前のファイルを見つけます。

    ![スーパーマーケットで買い物かごを持っている人の画像](./media/analyze-images-vision/store-camera-2.jpg)

1. **store-camera-2.jpg** ファイルをアップロードします。

1. 画像から抽出されたタグの一覧と、検出された属性パネルのそれぞれの自信度スコアを確認します。 ここで自信度スコアとは、検出された属性のテキストが画像内の実際の内容を説明している確率のことです。 タグの一覧には、物体だけでなく、"買い物"、"販売"、"立っている" などの行動も含まれています。******

    ![Vision Studio の [Detected attributes]\(検出された属性\) パネルのスクリーンショット。元の画像の横にテキストと自信度スコアがあります。](./media/analyze-images-vision/detect-attributes.png)

## オブジェクトの検出

このタスクでは、画像解析の**物体検出**機能を使用します。 物体検出は、認識可能な何千もの物体と生き物に基づいて境界ボックスを検出して抽出します。

1. Azure AI Foundry の *[Vision + Document]* ページに戻り、**[画像]** タブを選択し、**[一般的なオブジェクト検出]** タイルを選択します。

1. ダウンロードした画像を含むフォルダーを開き、次のような **store-camera-3.jpg** という名前のファイルを見つけます。

    ![ショッピングカートを持っている人の画像](./media/analyze-images-vision/store-camera-3.jpg)

1. **store-camera-3.jpg** ファイルをアップロードします。

1. **[Detected attributes]\(検出された属性\)** ボックスで、検出された物体とその自信度スコアの一覧を確認します。

1. **[Detected attributes]\(検出された属性\)** 一覧内の物体の上にマウス カーソルを置くと、画像内のその物体の境界ボックスが強調表示されます。

1. 右側に 70 という値が表示されるまで **[しきい値]** スライダーを移動します。 一覧内の物体に対して何が起こるかを観察します。 しきい値スライダーは、自信度スコアつまり確率がしきい値より高いと識別された物体のみを表示することを指定します。

## クリーンアップ

これ以上の演習を行わない場合は、不要になったリソースを削除します。 これにより、不要なコストが発生することを防ぎます。

1.  [Azure portal]( https://portal.azure.com) を開き、作成したリソースを含むリソース グループを選択します。 
1.  リソースを選択し、**[削除]** を、次に **[はい]** を選択して確定します。 これでリソースが削除されます。

## 詳細情報

このサービスでできることについて詳しくは、[Azure AI Vision に関するページ](https://learn.microsoft.com/azure/ai-services/computer-vision/overview)を参照してください。
