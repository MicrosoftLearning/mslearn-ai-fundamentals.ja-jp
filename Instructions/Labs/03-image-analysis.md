---
lab:
  title: Azure AI Foundry ポータルで画像を分析する
---

# Azure AI Foundry ポータルで画像を分析する

**Azure AI Vision** には、画像のコンテンツとコンテキストを理解し、画像から情報を抽出するための多数の機能が含まれています。 この演習では、インテリジェント なアプリケーションを作成するための Microsoft のプラットフォームである Azure AI Foundry ポータルで Azure AI Vision を使用し、組み込みの試行エクスペリエンスを使って画像を分析します。 

AI サービスが店舗を監視して支援を必要とする顧客を特定し、従業員に支援を指示する "スマート ストア" を実装することを架空の小売業者 *Northwind Traders* が決定したとします。 Azure AI Vision を使用すると、カメラで撮影した店舗全体の画像が分析されて、画像が表す内容のわかりやすい説明を受け取ることができます。

## Azure AI Foundry ポータルでプロジェクトを作成する

1. Web ブラウザーで [Azure AI Foundry ポータル](https://ai.azure.com) (`https://ai.azure.com`) を開き、Azure 資格情報を使用してサインインします。 初めてサインインしたときに開かれたヒントまたはクイック スタート ペインを閉じます。 

1. ブラウザーで `https://ai.azure.com/managementCenter/allResources` に移動し、**[作成]** を選択します。 次に、新しい *AI ハブ リソース*を作成するオプションを選択します。

1. *[プロジェクトの作成]* ウィザードで、有効なプロジェクト名を入力し、既存のハブが推奨された場合は、*新しい*ハブを作成するオプションを選択します。 

1. *[詳細オプション]* を展開し、プロジェクト用に次の設定を指定します。
    - **サブスクリプション**:お使いの Azure サブスクリプション
    - **リソース グループ**: リソース グループを作成または選択します
    - **リージョン**: 次のいずれかの場所を選択してください。
        * 米国東部
        * フランス中部
        * 韓国中部
        * 西ヨーロッパ
        * 米国西部

    プロジェクトとハブが作成されるまで待ちます。

1. プロジェクトが作成されると、プロジェクトの詳細の*概要*ページに移動します。 左側のメニューで **[AI サービス]** を選択します (場合によっては、上部のアイコンをクリックしてメニューを展開し、その内容を読み取る必要があります)。 

1. *[AI サービス]* ページで、*[Vision + Document]* タイルを選択して、Azure AI Vision とドキュメントの機能を試します。

    ![Azure AI Foundry の [Vision + Document] タイルのスクリーンショット。](./media/vision-document-tile.png)

## 画像のキャプションを生成する

Azure AI Vision の画像キャプション機能を使用して、*Northwind Traders* ストア内のカメラで撮影された画像を分析してみましょう。 画像のキャプションには、**キャプション**機能と**高密度キャプション**機能からアクセスできます。

1. *[Vision + Document]* ページで、下にスクロールし、*[その他のすべての Vision 機能の表示]* の下にある **[画像]** を選択します。 次に、**[画像キャプション]** タイルを選択します。

    ![[Vision and Document] ページの [画像] セクションの [画像キャプション] タイルのスクリーンショット。](./media/vision-image-captioning-tile.png)

1. **[画像にキャプションを追加する]** ページで、作成した *Azure AI サービス* リソースを選択します。 

1. **[画像にキャプションを追加する]** ページで、**試してみる**という小見出しの下に表示されている接続先のリソースを確認します。 変更を加える必要はありません。 (*注*: リソースの作成時に有効なリソースの場所をカスタマイズしなかった場合は、有効なリージョンにある新しい Azure AI サービスのリソースを作成するように求められる場合があります。 ラボを続行するには、新しいリソースを作成する必要があります)。  

1. [**https://aka.ms/mslearn-images-for-analysis**](https://aka.ms/mslearn-images-for-analysis) を選択して、**image-analysis.zip** をダウンロードします。 ご使用のコンピューターでそのフォルダーを開き、**store-camera-1.jpg** という名前のファイルを見つけます。これには次の画像が含まれています。

    ![Cellphone カメラを使用してストア内の子どもの画像を撮影している親の画像](./media/analyze-images-vision/store-camera-1.jpg)

1. **[ファイルをこちらにドラッグ アンド ドロップ]** ボックスにドラッグするか、ファイル システムでファイルを参照して、**store-camera-1.jpg** イメージをアップロードします。

1. 画像の右側にある **[Detected attributes]\(検出された属性\)** パネルに表示される、生成されたキャプション テキストを確認します。

    **キャプション**機能は、画像の内容を説明し、人間が判読可能な 1 つの英文を提供します。

1. 次に、同じ画像を使用して、**高密度キャプション**を実行します。 ページの上部にある *戻る* 矢印を選択して、**[Vision + Document]** ページに戻ります。 *[Vision + Document]* ページで、**[画像]** タブを選択して、**[高密度キャプション]** タイルを選択します。

    **高密度キャプション**機能は、画像に人間が判読可能な複数のキャプションを提供するという点で、**キャプション**機能とは異なります。1 つは画像のコンテンツを説明し、その他はそれぞれ画像で検出された重要な物体について取り上げます。 検出された各物体には境界ボックスが含まれていて、物体に関連付けられている画像内のピクセル座標を定義します。

1. **[Detected attributes]\(検出された属性\)** の一覧のいずれかのキャプションにカーソルを合わせ、画像内で何が起こるかを観察します。

    ![画像とそのキャプションが表示されています。](./media/analyze-images-vision/dense-captioning.png)

    一覧内の他のキャプションの上にマウス カーソルを移動し、画像内の境界ボックスが移動して、キャプションの生成に使用される画像の部分を強調表示するようすを確認します。

## イメージへのタグ付け 

次に試す機能は、*タグの抽出*機能です。 タグの抽出は、数千個の認識可能な物体 (生物、風景、行動など) に基づきます。

1. Azure AI Foundry の *[Vision + Document]* ページに戻り、**[画像]** タブを選択し、**[一般的なタグ抽出]** タイルを選択します。

1. ダウンロードした画像を含むフォルダーを開き、次のような **store-image-2.jpg** という名前のファイルを見つけます。

    ![スーパーマーケットで買い物かごを持っている人の画像](./media/analyze-images-vision/store-camera-2.jpg)

1. **store-camera-2.jpg** ファイルをアップロードします。

1. 画像から抽出されたタグの一覧と、検出された属性パネルのそれぞれの自信度スコアを確認します。 ここで自信度スコアとは、検出された属性のテキストが画像内の実際の内容を説明している確率のことです。 タグの一覧には、物体だけでなく、"買い物"、"販売"、"立っている" などの行動も含まれています。******

    ![Vision Studio の [Detected attributes]\(検出された属性\) パネルのスクリーンショット。元の画像の横にテキストと自信度スコアがあります。](./media/analyze-images-vision/detect-attributes.png)

## オブジェクトの検出

このタスクでは、画像解析の**物体検出**機能を使用します。 物体検出は、認識可能な何千もの物体と生き物に基づいて境界ボックスを検出して抽出します。

1. Azure AI Foundry の *[Vision + Document]* ページに戻り、**[画像]** タブを選択し、**[一般的なオブジェクト検出]** タイルを選択します。

1. ダウンロードした画像を含むフォルダーを開き、次のような **store-camera-3.jpg** という名前のファイルを見つけます。

    ![ショッピングカートを持っている人の画像](./media/analyze-images-vision/store-camera-3.jpg)

1. **store-camera-3.jpg** ファイルをアップロードします。

1. **[Detected attributes]\(検出された属性\)** ボックスで、検出された物体とその自信度スコアの一覧を確認します。

1. **[Detected attributes]\(検出された属性\)** 一覧内の物体の上にマウス カーソルを置くと、画像内のその物体の境界ボックスが強調表示されます。

1. 右側に 70 という値が表示されるまで **[しきい値]** スライダーを移動します。 一覧内の物体に対して何が起こるかを観察します。 しきい値スライダーは、自信度スコアつまり確率がしきい値より高いと識別された物体のみを表示することを指定します。

## クリーンアップ

これ以上の演習を行わない場合は、不要になったリソースを削除します。 これにより、不要なコストが発生することを防ぎます。

1.  [Azure portal]( https://portal.azure.com) を開き、作成したリソースを含むリソース グループを選択します。 
1.  リソースを選択し、**[削除]** を、次に **[はい]** を選択して確定します。 これでリソースが削除されます。

## 詳細情報

このサービスでできることについて詳しくは、[Azure AI Vision に関するページ](https://learn.microsoft.com/azure/ai-services/computer-vision/overview)を参照してください。
