---
lab:
  title: Vision Studio で画像を分析する
---

# Vision Studio で画像を分析する 

**Azure AI Vision** には、画像のコンテンツとコンテキストを理解し、画像から情報を抽出するための多数の機能が含まれています。 Azure AI Vision Studio を使用すると、画像解析の多くの機能を試すことができます。 

この演習では、Vision Studio を使い、組み込みの試行エクスペリエンスを使って画像を分析します。 AI サービスが店舗を監視して支援を必要とする顧客を特定し、従業員に支援を指示する "スマート ストア" を実装することを架空の小売業者 *Northwind Traders* が決定したとします。 Azure AI Vision を使用すると、カメラで撮影した店舗全体の画像が分析されて、画像が表す内容のわかりやすい説明を受け取ることができます。

## "Azure AI サービス" リソースを作成する**

Azure AI Vision の画像解析機能は、**Azure AI サービス**のマルチサービス リソースで使用できます。 まだ作成していない場合は、Azure サブスクリプションで **Azure AI サービス** リソースを作成します。

1. 別のブラウザー タブで Azure portal ([https://portal.azure.com](https://portal.azure.com?azure-portal=true)) を開き、ご使用の Azure サブスクリプションに関連付けられている Microsoft アカウントを使用してサインインします。

1. **[&#65291;リソースの作成]** ボタンをクリックし、「Azure AI サービス」を検索してください。** **[Azure AI** **サービスの作成]** プランを選択してください。 Azure AI サービス リソースを作成するためのページに移動します。 これを以下の設定で構成します。
    - **[サブスクリプション]**: *お使いの Azure サブスクリプション*。
    - **[リソース グループ]**: *一意の名前のリソース グループを選択するか、作成します*。
    - **[リージョン]**: 米国東部。
    - **[名前]**: *一意の名前を入力します*。
    - **価格レベル**: *Standard S0。*
    - **[このボックスをオンにすることにより、以下のすべてのご契約条件を読み、同意したものとみなされます]**:*オン*。

1. **[確認 + 作成]**、**[作成]** の順に選択し、デプロイが完了するまで待ちます。

## Azure AI サービス リソースを Vision Studio に接続する

次に、上記でプロビジョニングした Azure AI サービス リソースを Vision Studio に接続します。

1. 別のブラウザー タブで、[Vision Studio](https://portal.vision.cognitive.azure.com?azure-portal=true) にアクセスします。

1. ご使用のアカウントでサインインし、Azure AI サービス リソースを作成したのと同じディレクトリを使用していることを確認します。

1. Vision Studio のホーム ページで、**[Vision の利用を始める]** 見出しの下にある **[すべてのリソースを表示]** を選択します。

    ![[すべてのリソースを表示] リンクが、Vision Studio の [Vision の利用を始める] の下で強調表示されています。](./media/analyze-images-vision/vision-resources.png)

1. **[Select a resource to work with]\(操作するリソースの選択\)** ページで、上記で作成した一覧内のリソース上にマウス カーソルを置き、リソース名の左側にあるチェック ボックスをオンにしてから、**[Select as default resource]\(既定のリソースとして選択\)** を選択します。

    > **注**:リソースが一覧にない場合は、ページを **[更新]** することが必要な場合があります。

    ![[Select a resource to work with]\(操作するリソースの選択\) ダイアログが表示され、cog-ms-learn-vision-SUFFIX Cognitive Services リソースが強調表示されてオンになっています。 [Select as default resource]\(既定のリソースとして選択\) ボタンが強調表示されています。](./media/analyze-images-vision/default-resource.png)

1. 画面の右上にある [x] を選択して、設定ページを閉じます。

## 画像のキャプションを生成する

これで、Vision Studio を使用して、*Northwind Traders* の店舗でカメラによって撮影された画像を分析する準備ができました。

Azure AI Vision の画像キャプション機能を見てみましょう。 画像のキャプションには、**キャプション**機能と**高密度キャプション**機能からアクセスできます。

1. Web ブラウザーで、[Vision Studio](https://portal.vision.cognitive.azure.com?azure-portal=true) に移動します。

1. **[Vision の使用を始める]** ランディング ページで、**[画像解析]** タブを選択し、次に **[Add captions to images]\(画像にキャプションを追加する\)** タイルを選択します。

    ![Vision Studio のホーム ページで、[画像解析] タブが選択され、強調表示されています。 [Add captions to images]\(画像にキャプションを追加する\) タイルが強調表示されています。](./media/analyze-images-vision/add-captions.png)

1. **[Try It Out]\(試してみる\)** 小見出しで、リソース利用ポリシーを読んでチェック ボックスをオンにすることで承諾します。  

1. [**https://aka.ms/mslearn-images-for-analysis**](https://aka.ms/mslearn-images-for-analysis) を選択して、**image-analysis.zip** をダウンロードします。 ご使用のコンピューターでそのフォルダーを開き、**store-camera-1.jpg** という名前のファイルを見つけます。これには次の画像が含まれています。

    ![Cellphone カメラを使用してストア内の子どもの画像を撮影している親の画像](./media/analyze-images-vision/store-camera-1.jpg)

1. **[ファイルをこちらにドラッグ アンド ドロップ]** ボックスにドラッグするか、ファイル システムでファイルを参照して、**store-camera-1.jpg** イメージをアップロードします。

1. 画像の右側にある **[Detected attributes]\(検出された属性\)** パネルに表示される、生成されたキャプション テキストを確認します。

    **キャプション**機能は、画像の内容を説明し、人間が判読可能な 1 つの英文を提供します。

1. 次に、同じ画像を使用して、**高密度キャプション**を実行します。 **Vision Studio** ホーム ページに戻り、前に行ったように、**[画像解析]** タブを選択し、次に **[Dense captioning]\(高密度キャプション\)** タイルを選択します。

    **高密度キャプション**機能は、画像に人間が判読可能な複数のキャプションを提供するという点で、**キャプション**機能とは異なります。1 つは画像のコンテンツを説明し、その他はそれぞれ画像で検出された重要な物体について取り上げます。 検出された各物体には境界ボックスが含まれていて、物体に関連付けられている画像内のピクセル座標を定義します。

1. **[Detected attributes]\(検出された属性\)** の一覧のいずれかのキャプションにカーソルを合わせ、画像内で何が起こるかを観察します。

    ![画像とそのキャプションが表示されています。](./media/analyze-images-vision/dense-captioning.png)

    一覧内の他のキャプションの上にマウス カーソルを移動し、画像内の境界ボックスが移動して、キャプションの生成に使用される画像の部分を強調表示するようすを確認します。

## イメージへのタグ付け

次に試す機能は、**タグの抽出**機能です。 タグの抽出は、数千個の認識可能な物体 (生物、風景、行動など) に基づきます。

1. Vision Studio のホーム ページに戻り、**[画像解析]** タブの下にある **[Extract common tags from images]\(画像から共通のタグを抽出する\)** タイルを選択します。

2. **[Choose the model you want to try out]\(試すモデルを選択\)** で、**[Prebuilt product vs. gap model]\(商品と空きの事前構築済みモデル\)** を選択状態のままにします。 **[言語の選択]** で、**[English]** または好みの言語を選択します。

3. ダウンロードした画像を含むフォルダーを開き、次のような **store-image-2.jpg** という名前のファイルを見つけます。

    ![スーパーマーケットで買い物かごを持っている人の画像](./media/analyze-images-vision/store-camera-2.jpg)

4. **store-camera-2.jpg** ファイルをアップロードします。

5. 画像から抽出されたタグの一覧と、検出された属性パネルのそれぞれの自信度スコアを確認します。 ここで自信度スコアとは、検出された属性のテキストが画像内の実際の内容を説明している確率のことです。 タグの一覧には、物体だけでなく、"買い物"、"販売"、"立っている" などの行動も含まれています。******

    ![Vision Studio の [Detected attributes]\(検出された属性\) パネルのスクリーンショット。元の画像の横にテキストと自信度スコアがあります。](./media/analyze-images-vision/detect-attributes.png)

## オブジェクトの検出

このタスクでは、画像解析の**物体検出**機能を使用します。 物体検出は、認識可能な何千もの物体と生き物に基づいて境界ボックスを検出して抽出します。

1. Vision Studio のホーム ページに戻り、**[画像解析]** タブの下にある **[Detect common objects in images]\(画像内の一般的な物体を検出する\)** タイルを選択します。

1. **[Choose the model you want to try out]\(試すモデルを選択\)** で、**[Prebuilt product vs. gap model]\(商品と空きの事前構築済みモデル\)** を選択状態のままにします。

1. ダウンロードした画像を含むフォルダーを開き、次のような **store-camera-3.jpg** という名前のファイルを見つけます。

    ![ショッピングカートを持っている人の画像](./media/analyze-images-vision/store-camera-3.jpg)

1. **store-camera-3.jpg** ファイルをアップロードします。

1. **[Detected attributes]\(検出された属性\)** ボックスで、検出された物体とその自信度スコアの一覧を確認します。

1. **[Detected attributes]\(検出された属性\)** 一覧内の物体の上にマウス カーソルを置くと、画像内のその物体の境界ボックスが強調表示されます。

1. 右側に 70 という値が表示されるまで **[しきい値]** スライダーを移動します。 一覧内の物体に対して何が起こるかを観察します。 しきい値スライダーは、自信度スコアつまり確率がしきい値より高いと識別された物体のみを表示することを指定します。

## クリーンアップ

これ以上の演習を行わない場合は、不要になったリソースを削除します。 これにより、不要なコストが発生することを防ぎます。

1.  [Azure portal]( https://portal.azure.com) を開き、作成したリソースを含むリソース グループを選択します。 
1.  リソースを選択し、**[削除]** を、次に **[はい]** を選択して確定します。 これでリソースが削除されます。

## 詳細情報

このサービスでできることについて詳しくは、[Azure AI Vision に関するページ](https://learn.microsoft.com/azure/ai-services/computer-vision/overview)を参照してください。
