---
lab:
  title: Azure AI Foundry ポータルで画像を分析する
---

# Azure AI Foundry ポータルで画像を分析する

**Azure AI Vision** には、画像のコンテンツとコンテキストを理解し、画像から情報を抽出するための多数の機能が含まれています。 この演習では、インテリジェント なアプリケーションを作成するための Microsoft のプラットフォームである Azure AI Foundry ポータルで Azure AI Vision を使用し、組み込みの試行エクスペリエンスを使って画像を分析します。 

AI サービスが店舗を監視して支援を必要とする顧客を特定し、従業員に支援を指示する "スマート ストア" を実装することを架空の小売業者 *Northwind Traders* が決定したとします。 Azure AI Vision を使用すると、カメラで撮影した店舗全体の画像が分析されて、画像が表す内容のわかりやすい説明を受け取ることができます。

## Azure AI Foundry ポータルでプロジェクトを作成する

1. ブラウザー タブ内で、[Azure AI Foundry](https://ai.azure.com?azure-portal=true) に移動します。

1. ご自分のアカウントでサインインします。 

1. Azure AI Foundry ポータルのホーム ページで **[プロジェクトの作成]** を選択します。 Azure AI Foundry では、プロジェクトは作業を整理するのに役立つコンテナーです。  

    ![プロジェクトの作成が選択されている Azure AI Foundry ホーム ページのスクリーンショット。](./media/azure-ai-foundry-home-page.png)

1. *[プロジェクトの作成]* ウィンドウに、生成されたプロジェクト名が表示され、そのまま保持できます。 過去にハブを作成したかどうかに応じて、作成する*新しい* Azure リソースの一覧または既存のハブのドロップダウン リストが表示されます。 既存のハブのドロップダウン リストが表示される場合は、 *[新しいハブの作成]* を選択し、ハブの一意の名前を作成して、*[次へ]* を選択します。  
 
    ![ハブとプロジェクトの名前が自動的に生成された [プロジェクトの作成] ウィンドウのスクリーンショット。](./media/azure-ai-foundry-create-project.png)

    > **重要**: ラボの残りの部分を完了するには、特定の場所にプロビジョニングされた Azure AI サービスのリソースが必要です。

1. 同じ *[プロジェクトの作成]* ウィンドウで、**[カスタマイズ]** を選択し、*米国東部、フランス中部、韓国中部、西ヨーロッパ、または米国西部*のいずれかの**場所**を選択して、ラボの残りの部分を完了します。 **[次へ]**、**[作成]** の順に選択します。 

1. 作成されるリソースを書き留めます。 
    - Az AI サービス
    - Azure AI ハブ
    - Azure AI プロジェクト
    - ストレージ アカウント
    - Key Vault
    - リソース グループ  
 
1. リソースが作成されると、プロジェクトの *[概要]* ページに移動します。 画面の左側のメニューで、**[AI サービス]** を選択します。
 
    ![[AI サービス] が選択されているプロジェクト画面の左側のメニューのスクリーンショット。](./media/azure-ai-foundry-ai-services.png)  

1. *[AI サービス]* ページで、*[Vision + Document]* タイルを選択して、Azure AI Vision とドキュメントの機能を試します。

    ![[AI サービス] ページで選択されている [Vision and Document] タイルのスクリーンショット。](./media/vision-document-tile.png)

## 画像のキャプションを生成する

Azure AI Vision の画像キャプション機能を使用して、*Northwind Traders* ストア内のカメラで撮影された画像を分析してみましょう。 画像のキャプションには、**キャプション**機能と**高密度キャプション**機能からアクセスできます。

1. *[Vision + Document]* ページで、下にスクロールし、*[その他のすべての Vision 機能の表示]* の下にある **[画像]** を選択します。 次に、**[画像キャプション]** タイルを選択します。

    ![[Vision and Document] ページの [画像] セクションの [画像キャプション] タイルのスクリーンショット。](./media/vision-image-captioning-tile.png)

1. **[画像にキャプションを追加する]** ページで、**試してみる**という小見出しの下に表示されている接続先のリソースを確認します。 変更を加える必要はありません。 (*注*: リソースの作成時に有効なリソースの場所をカスタマイズしなかった場合は、有効なリージョンにある新しい Azure AI サービスのリソースを作成するように求められる場合があります。 ラボを続行するには、新しいリソースを作成する必要があります)。  

1. [**https://aka.ms/mslearn-images-for-analysis**](https://aka.ms/mslearn-images-for-analysis) を選択して、**image-analysis.zip** をダウンロードします。 ご使用のコンピューターでそのフォルダーを開き、**store-camera-1.jpg** という名前のファイルを見つけます。これには次の画像が含まれています。

    ![Cellphone カメラを使用してストア内の子どもの画像を撮影している親の画像](./media/analyze-images-vision/store-camera-1.jpg)

1. **[ファイルをこちらにドラッグ アンド ドロップ]** ボックスにドラッグするか、ファイル システムでファイルを参照して、**store-camera-1.jpg** イメージをアップロードします。

1. 画像の右側にある **[Detected attributes]\(検出された属性\)** パネルに表示される、生成されたキャプション テキストを確認します。

    **キャプション**機能は、画像の内容を説明し、人間が判読可能な 1 つの英文を提供します。

1. 次に、同じ画像を使用して、**高密度キャプション**を実行します。 ページの上部にある *戻る* 矢印を選択して、**[Vision + Document]** ページに戻ります。 *[Vision + Document]* ページで、**[画像]** タブを選択して、**[高密度キャプション]** タイルを選択します。

    **高密度キャプション**機能は、画像に人間が判読可能な複数のキャプションを提供するという点で、**キャプション**機能とは異なります。1 つは画像のコンテンツを説明し、その他はそれぞれ画像で検出された重要な物体について取り上げます。 検出された各物体には境界ボックスが含まれていて、物体に関連付けられている画像内のピクセル座標を定義します。

1. **[Detected attributes]\(検出された属性\)** の一覧のいずれかのキャプションにカーソルを合わせ、画像内で何が起こるかを観察します。

    ![画像とそのキャプションが表示されています。](./media/analyze-images-vision/dense-captioning.png)

    一覧内の他のキャプションの上にマウス カーソルを移動し、画像内の境界ボックスが移動して、キャプションの生成に使用される画像の部分を強調表示するようすを確認します。

## イメージへのタグ付け 

次に試す機能は、*タグの抽出*機能です。 タグの抽出は、数千個の認識可能な物体 (生物、風景、行動など) に基づきます。

1. Azure AI Foundry の *[Vision + Document]* ページに戻り、**[画像]** タブを選択し、**[一般的なタグ抽出]** タイルを選択します。

2. **[Choose the model you want to try out]\(試すモデルを選択\)** で、**[Prebuilt product vs. gap model]\(商品と空きの事前構築済みモデル\)** を選択状態のままにします。 **[言語の選択]** で、**[English]** または好みの言語を選択します。

3. ダウンロードした画像を含むフォルダーを開き、次のような **store-image-2.jpg** という名前のファイルを見つけます。

    ![スーパーマーケットで買い物かごを持っている人の画像](./media/analyze-images-vision/store-camera-2.jpg)

4. **store-camera-2.jpg** ファイルをアップロードします。

5. 画像から抽出されたタグの一覧と、検出された属性パネルのそれぞれの自信度スコアを確認します。 ここで自信度スコアとは、検出された属性のテキストが画像内の実際の内容を説明している確率のことです。 タグの一覧には、物体だけでなく、"買い物"、"販売"、"立っている" などの行動も含まれています。******

    ![Vision Studio の [Detected attributes]\(検出された属性\) パネルのスクリーンショット。元の画像の横にテキストと自信度スコアがあります。](./media/analyze-images-vision/detect-attributes.png)

## オブジェクトの検出

このタスクでは、画像解析の**物体検出**機能を使用します。 物体検出は、認識可能な何千もの物体と生き物に基づいて境界ボックスを検出して抽出します。

1. Azure AI Foundry の *[Vision + Document]* ページに戻り、**[画像]** タブを選択し、**[一般的なオブジェクト検出]** タイルを選択します。

1. **[Choose the model you want to try out]\(試すモデルを選択\)** で、**[Prebuilt product vs. gap model]\(商品と空きの事前構築済みモデル\)** を選択状態のままにします。

1. ダウンロードした画像を含むフォルダーを開き、次のような **store-camera-3.jpg** という名前のファイルを見つけます。

    ![ショッピングカートを持っている人の画像](./media/analyze-images-vision/store-camera-3.jpg)

1. **store-camera-3.jpg** ファイルをアップロードします。

1. **[Detected attributes]\(検出された属性\)** ボックスで、検出された物体とその自信度スコアの一覧を確認します。

1. **[Detected attributes]\(検出された属性\)** 一覧内の物体の上にマウス カーソルを置くと、画像内のその物体の境界ボックスが強調表示されます。

1. 右側に 70 という値が表示されるまで **[しきい値]** スライダーを移動します。 一覧内の物体に対して何が起こるかを観察します。 しきい値スライダーは、自信度スコアつまり確率がしきい値より高いと識別された物体のみを表示することを指定します。

## クリーンアップ

これ以上の演習を行わない場合は、不要になったリソースを削除します。 これにより、不要なコストが発生することを防ぎます。

1.  [Azure portal]( https://portal.azure.com) を開き、作成したリソースを含むリソース グループを選択します。 
1.  リソースを選択し、**[削除]** を、次に **[はい]** を選択して確定します。 これでリソースが削除されます。

## 詳細情報

このサービスでできることについて詳しくは、[Azure AI Vision に関するページ](https://learn.microsoft.com/azure/ai-services/computer-vision/overview)を参照してください。
