---
lab:
  title: 新しい Microsoft Foundry ポータルの音声について確認する
---

# 新しい Microsoft Foundry ポータルの音声について確認する

この演習では、Microsoft のプラットフォームを使用して AI アプリケーションである Microsoft Foundry を作成し、音声を使用して生成 AI モデルと対話します。 エージェント アプリケーションを通じて、Azure Speech の音声テキスト変換 (STT) とテキスト音声変換 (TTS) の機能を確認します。

> **注**:この演習では、"新しい" Foundry ユーザー インターフェイスを利用します。** 

この演習は約 **20** 分かかります。

## Microsoft Foundry でプロジェクトを作成する

1. Web ブラウザーで、[Microsoft Foundry](https://ai.azure.com) (`https://ai.azure.com`) を開き、Azure 資格情報を使用してサインインします。 初めてサインインする場合に開かれるヒントまたはクイック スタートのペインを閉じ、必要に応じて、左上にある **[Foundry]** ロゴを使用してホーム ページに移動します。次の図のようなページが表示されます (**[ヘルプ]** ペインが表示される場合は閉じます)。

    ![新しい Foundry のトグルが強調表示されている Microsoft Foundry ホーム ページのスクリーンショット。](./media/foundry-home-page-classic.png)

1. 画面の上部にある **[新しい Foundry]** のトグルを選択します。 

1. 新しい Foundry ユーザー インターフェイスを利用するには、サポートされているリージョンにプロジェクトを作成する必要があります。 ドロップダウン メニューで **[新しいプロジェクトの作成]** を選択します。 (*注*: サブスクリプションに他のプロジェクトが作成されていて、サポートされているリージョンにデプロイされている場合は、ドロップダウン リストにも表示されます)。

    ![新しい Foundry UI にアクセスするためのプロジェクト選択メニューのスクリーンショット。](./media/create-project-new-foundry.png)

1. **プロジェクトの作成**ウィザードで、プロジェクトの有効な名前を入力します。 次に、**[詳細オプション]** を展開し、プロジェクト用に次の設定を指定します。
    - **Foundry リソース**: *AI Foundry リソースに有効な名前を入力します。*
    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **リソース グループ**: *リソース グループを作成または選択します*
    - **[リージョン]**: **Foundry で推奨される**リージョンのいずれかを選択します\*
    
    \**モデル デプロイは、リージョンのクォータによって制限されます。使用可能なクォータが不足しているリージョンを選択した場合、後で新しいリソースの代替リージョンを選択しなければならない場合があります。*

1. **［作成］** を選択します プロジェクトが作成されるまで待ちます。 これには数分かかることがあります。

## 音声プレイグラウンド アプリを開く

1. プロジェクトが作成されると、新しい Foundry ホーム ページが表示されます。 ホーム ページで、右上のメニューに移動します (メニュー オプションを表示するには、画面を展開する必要がある場合があります)。 **[Build]\(ビルド\)** を選択します。 

    ![[ビルド] メニュー オプションに移動する方法のスクリーンショット。](./media/0126-new-foundry-home-build-selected.png)
  
1. *[ビルド]* ページで **[モデル]** を選択し、**[AI サービス]** を選択します。 AI サービスの一覧が、Foundry Tools で使用できるすべての AI 機能の小さなサブセットになっていることを確認してください。 一覧から **[Azure Speech - 音声ライブ]** を選択して、音声プレイグラウンドで *[音声ライブ]* 機能を試します。 

    ![音声プレイグラウンドに移動して [Azure Speech - 音声ライブ] をテストする方法のスクリーンショット。](./media/0126-new-foundry-ai-services-voice-live.png)

## 音声ライブ エージェントをテストする 
 
音声対応アプリケーションを強化する 2 つの基本的な音声機能は、音声認識 (単語の音声をテキストに変換する) と音声合成 (テキストを自然な音声に変換する) です。 音声プレイグラウンドの音声ライブでは、音声認識と音声合成の両方がサポートされているため、モデルと音声ベースの会話ができます。 音声ライブでは、いくつかの Azure Speech 機能が組み合わされています。この機能は、カスタマー サービスの例でテストします。 

1. まずは、生成 AI モデルとチャットしてみましょう。 生成 AI モデルは、音声ベースのサポートを受ける*エージェント* エクスペリエンスを強化します。 [チャット] ペインで **[スタート]** を選択して、モデルとの会話を開始します。 メッセージが表示されたら、システム マイクへのアクセスを許可します。 

    ![[Azure Speech - 音声ライブ] がテスト用に開かれている音声プレイグラウンドのスクリーンショット。](./media/0126-new-foundry-voice-playground-start.png)

1. 状態が **[話しています...]** に変わっていることがわかります。 エージェントが、テキスト音声変換を使用して、モデルからの応答を音声化します。 エージェントが、希望の旅行先を尋ねて会話を開始します。
 
1. **[CC]** ボタンを選択すると、音声プロンプトと応答のテキストが表示されます。

    ![クローズド キャプションを表示する [CC] ボタンが選択されているスクリーンショット。](./media/0126-new-foundry-voice-show-text.png)

1. アプリの状態が **[聞いています...]** のときに、**"フランスのパリの旅行計画を立てて"** のように話し、 応答を待ちます。 アプリが音声入力を処理し、音声テキスト変換を使用して音声をテキストに変換し、プロンプトとしてモデルに送信します。

1. 時間がある場合は、現在のシナリオを引き続きテストできます。 完了したら、**[x]** を選択して会話を終了します。 音声モードを終了すると、会話のテキストのトランスクリプトが表示されます。 

## エージェントの構成を理解する

今操作した音声ライブ エージェントには、いくつかの既定の構成があります。 こちらを見てみましょう。

1. このプレイグラウンドで使用されている生成 AI モデルを確認します。 この場合、使用されるモデルは *GPT Realtime* です。 モデルを変更する方法を確認します。 より小さい言語モデル (*Microsoft Phi 3 Mini* など) を使用するのか、現在使用されているようなより大きな言語モデルを引き続き使用するのかを検討してください。 

    ![プレイグラウンドでの構成を設定する生成 AI モデル セクションのスクリーンショット。](./media/0126-new-foundry-gpt-realtime.png)

    >**注**:設定に変更を加えるたびに、設定パネルの下部にある *[変更の適用]* を選択して更新プログラムを保存する必要があります。 

1. 生成 AI モデルの *[応答指示]* を確認します。 サンプルでは、応答指示が事前に書き込まれています。 応答指示を変更してエージェントの応答を変更する方法を検討してください。  
    
    ![プレイグラウンドの設定の [応答指示] セクションのスクリーンショット。](./media/0126-new-foundry-model-response-instruction.png)

1. 生成 AI モデルの *[詳細設定]* を確認します。 モデルの応答に影響を与えるもう 1 つの方法は、応答の *[温度]* を構成することです。 *[温度]* は、モデルの応答のランダム性または創造性を制御するパラメーターです。 モデルが低い温度に設定されると、その応答はより予測可能で事実に基づいたものになります。 温度が上昇すると、変動性と創造性が向上します。 このエージェントの既定の設定は非常に高いことがわかります。 温度を高く設定することは、ブレーンストーミングや、会話のトーン、さまざまな例の生成で便利です。 ただし、温度が高すぎると、応答が意味をなさず、信頼性が低下する可能性があります。

    ![モデルの温度設定のスクリーンショット。](./media/0126-new-foundry-temperature.png)

1. *[音声入力]* セクションを確認します。 モデルが既定で言語を自動検出できることがわかります。 また、特定の言語を認識するように設定することもできます。 言語構成を使用すると、モデルがエージェントに対するユーザーの入力を解釈できます。

    ![プレイグラウンドの設定の音声入力セクションのスクリーンショット。](./media/0126-new-foundry-voice-speech-input.png)

1. *[音声出力]* セクションを確認します。 音声出力に使用される音声を特定し、変更してみてください。 テキスト音声変換ソリューションでは、音声を使用して、生成された音声のリズム、発音、音質、その他の側面を制御します。 

    ![プレイグラウンドの設定の音声出力セクションのスクリーンショット。](./media/0126-new-foundry-voice-speech-output.png)

音声プレイグラウンドの音声ライブ機能には、アバターを選択するオプションも含まれています。 時間がある場合は、さまざまなアバターを試して、異なる音声とペアリングすることができます。 Azure Speech の機能の詳細については、[Azure Speech のドキュメント](https://learn.microsoft.com/azure/ai-services/speech-service/overview)にも記載されています。 完了したら、クリーン アップに進みます。 

## クリーンアップ

これ以上の演習を行わない場合は、不要になったリソースを削除します。 これにより、不要なコストが発生することを防ぎます。

1. [https://portal.azure.com](https://portal.azure.com) で **Azure portal** を開き、作成したリソースを含むリソース グループを選択します。
1. **[リソース グループの削除]** を選び、**リソース グループの名前を入力**して、確定します。 これでリソース グループが削除されます。