---
lab:
  title: Microsoft Foundry で画像を分析する
---

# Microsoft Foundry で画像を分析する

**Azure Vision** には、画像のコンテンツとコンテキストを理解し、画像から情報を抽出するための多数の機能が含まれています。 この演習では、インテリジェント アプリケーションを作成するための Microsoft のプラットフォームである Microsoft Foundry で Azure Vision を使用して、組み込みの評価エクスペリエンスを使って画像を分析します。 

AI サービスが店舗を監視して支援を必要とする顧客を特定し、従業員に支援を指示する "スマート ストア" を実装することを架空の小売業者 *Northwind Traders* が決定したとします。 Azure Vision を使用すると、カメラで撮影した店舗全体の画像を分析して、そこに写し出されたものについてわかりやすい説明を得ることができます。

この演習は約 **20** 分かかります。

## 画像ファイルのダウンロードと抽出

1. `https://aka.ms/mslearn-images-for-analysis` から **[image-analysis.zip](https://aka.ms/mslearn-images-for-analysis)** をダウンロードします。
1. ダウンロードした zip ファイルをコンピューター上のフォルダーに抽出します。

## Microsoft Foundry でプロジェクトを作成する

1. Web ブラウザーで、[Microsoft Foundry](https://ai.azure.com) (`https://ai.azure.com`) を開き、Azure 資格情報を使用してサインインします。 初めてサインインする場合に開かれるヒントまたはクイック スタートのペインを閉じ、必要に応じて、左上にある **[Foundry]** ロゴを使用してホーム ページに移動します。次の図のようなページが表示されます (**[ヘルプ]** ペインが表示される場合は閉じます)。

    ![Foundry のホーム ページのスクリーンショット。](./media/ai-foundry-portal.png)

1. ページの下部までスクロールし、**[Azure AI サービスを探す]** タイルを選択します。

    ![[Azure AI サービスを探す] タイルのスクリーンショット。](./media/ai-services.png)

1. [Azure AI サービス] ページで、**[Vision + ドキュメント]** タイルを選択します。

    ![[Vision + ドキュメント] タイルのスクリーンショット。](./media/vision-tile.png)

1. **[Vision + ドキュメント]** ページで、**[画像]** タブを選択して、**[画像キャプション]** タイルを選択します。

    ![[画像キャプション] タイルのスクリーンショット。](./media/image-captioning-tile.png)

1. **[画像へのキャプションの追加]** ペインで、**[ハブの選択]** ボタンを使用して、次の設定で**新しいハブを作成**します。
    - **[ハブ名]**:*ハブに有効な名前を入力します。*
    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **リソース グループ**: *リソース グループを作成または選択します*
    - **[場所]**: *次のいずれかの場所を選択してください*。
        - 米国東部
        - フランス中部
        - 韓国中部
        - 西ヨーロッパ
        - 米国西部
    - **[Azure AI サービスの接続]**: *有効な名前を持つ新しい Azure AI サービス リソースを作成します*
    - **Azure AI 検索への接続**:接続をスキップする

    \*"この演習の執筆時点では、Azure Vision がサポートされているのは、上記のリージョン内のハブです"**。

1. ハブが作成されると、プロジェクトを作成するように求められます。 適切なプロジェクト名を入力して **[プロジェクトの作成]** を選択します。

## 画像のキャプションを生成する

Azure Vision の画像キャプション機能を使用して、*Northwind Traders* の店舗内のカメラで撮影された画像を分析してみましょう。 画像のキャプションには、**キャプション**機能と**高密度キャプション**機能からアクセスできます。

1. 左側の作業ペインで、**[AI サービス]** を選択します。

    *ここで、前に使用した手順を繰り返して画像キャプション インターフェイスに戻り、新しいハブベースのプロジェクトを使用する必要があります。*

1. **[AI サービス]** ページの **[Vision + ドキュメント]** タイルを選択します。 次に、**[Vision + ドキュメント]** ページの **[画像]** タブで、**[画像キャプション]** タイルを選択します。

1. **[画像へのキャプションの追加]** ページの *[接続されている Azure AI サービス]* 選択メニューで、ハブに作成した Azure AI サービス リソースが選択されていることを確認します。

1. **[ファイルを参照する]** リンクを使用して、前にダウンロードして抽出したファイルから **store-camera-1.jpg** の画像をアップロードします。

1. 画像の右側にある **[Detected attributes]\(検出された属性\)** パネルに表示される、生成されたキャプション テキストを確認します。

    ![分析された画像を含む [画像へのキャプションの追加] ページのスクリーンショット。](./media/image-captioning.png)

    **キャプション**機能は、画像の内容を説明し、人間が判読可能な 1 つの英文を提供します。

1. 次に、同じ画像を使用して、**高密度キャプション**を実行します。 **[Vision + ドキュメント]** ページに戻るには、ページの上部にある **&larr;** *戻る*矢印を選択し、**[Vision + ドキュメント]** ページの **[画像]** タブで、**[高密度キャプション]** タイルを選択します。

    **高密度キャプション**機能は、画像に人間が判読可能な複数のキャプションを提供するという点で、**キャプション**機能とは異なります。1 つは画像のコンテンツを説明し、その他はそれぞれ画像で検出された重要な物体について取り上げます。 検出された各物体には境界ボックスが含まれていて、物体に関連付けられている画像内のピクセル座標を定義します。

1. **store-camera-1.jpg** の画像をもう一度アップロードし、高密度キャプションの結果を表示します。

    ![高密度キャプションの結果のスクリーンショット。](./media/dense-captioning.png)

    **[検出された属性]** 一覧のいずれかのキャプションにカーソルを合わせ、画像で検出された各物体に対してキャプションが生成されることを確認します。

## イメージへのタグ付け 

次に試す機能は、*タグの抽出*機能です。 タグの抽出は、数千個の認識可能な物体 (生物、風景、行動など) に基づきます。

1. ページの上部にある**&larr;** *戻る*矢印を選択して、**[Vision + ドキュメント]** ページに戻ります。 次に、**[Vision + ドキュメント]** ページの **[画像]** タブで、**[共通タグ抽出]** タイルを選択します。
1. 前に抽出したフォルダーから **store-camera-2.jpg** ファイルをアップロードします。
1. 画像から抽出されたタグの一覧と、検出された属性パネルのそれぞれの自信度スコアを確認します。 ここで自信度スコアとは、検出された属性のテキストが画像内の実際の内容を説明している確率のことです。 タグの一覧には、物体だけでなく、"買い物"、"販売"、"立っている" などの行動も含まれています。******

    ![Vision Studio の [Detected attributes]\(検出された属性\) パネルのスクリーンショット。元の画像の横にテキストと自信度スコアがあります。](./media/analyze-images-vision/detect-attributes.png)

## オブジェクトの検出

このタスクでは、画像解析の**物体検出**機能を使用します。 物体検出は、認識可能な何千もの物体と生き物に基づいて境界ボックスを検出して抽出します。

1. ページの上部にある**&larr;** *戻る*矢印を選択して、**[Vision + ドキュメント]** ページに戻ります。 次に、**[画像]** タブで、**[共通物体検出]** タイルを選択します。

1. **store-camera-3.jpg** ファイルをアップロードします。

1. **[Detected attributes]\(検出された属性\)** ボックスで、検出された物体とその自信度スコアの一覧を確認します。

    ![高密度キャプションの結果のスクリーンショット。](./media/object-detection.png)

1. **store-camera-4.jpg** 内の物体を検出してみてください

## クリーンアップ

これ以上の演習を行わない場合は、不要になったリソースを削除します。 これにより、不要なコストが発生することを防ぎます。

1. [Azure portal]( https://portal.azure.com) を開き、作成したリソースを含むリソース グループを選択します。 
1. **[リソース グループの削除]** を選び、**リソース グループの名前を入力**して、確定します。 これでリソース グループが削除されます。

## 詳細情報

このサービスで実行できる機能の詳細については、[Azure Vision のページ](https://learn.microsoft.com/azure/ai-services/computer-vision/overview)を参照してください。